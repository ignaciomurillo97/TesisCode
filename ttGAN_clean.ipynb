{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tilable terrain gan\n",
    "\n",
    "- DC GAN for now\n",
    "- pending tiling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (2.13.0)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (3.9.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (6.0)\n",
      "Requirement already satisfied: rasterio in /usr/local/lib/python3.8/dist-packages (1.3.8)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.56.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.13.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.23.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow) (0.32.0)\n",
      "Requirement already satisfied: affine in /usr/local/lib/python3.8/dist-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from rasterio) (23.1.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from rasterio) (2019.11.28)\n",
      "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.8/dist-packages (from rasterio) (8.1.7)\n",
      "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.8/dist-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from rasterio) (1.4.7)\n",
      "Requirement already satisfied: click-plugins in /usr/local/lib/python3.8/dist-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.8/dist-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow h5py pyyaml rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing in tensorflow\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Constants\n",
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = 28\n",
    "MAX_ALTITUDE = 1105\n",
    "MIN_ALTITUDE = -23\n",
    "\n",
    "# 1. Read the GeoTIFF files\n",
    "file_list = glob.glob(\"TesisCode/Dataset/download2/*.tif\")\n",
    "ds = tf.data.Dataset.from_tensor_slices(file_list)\n",
    "\n",
    "# 2. Decode and preprocess the images\n",
    "def decode_image(filename):\n",
    "    with rasterio.open(filename.numpy().decode('utf-8')) as src:\n",
    "        image = src.read()\n",
    "        image = image[0]\n",
    "        \n",
    "    # Resize to desired image size using TensorFlow\n",
    "    size_rows, size_cols = np.shape(image)\n",
    "    # random 28x28 crop of np array image\n",
    "    start_row = random.randint(0, size_rows - IMAGE_SIZE)\n",
    "    start_col = random.randint(0, size_cols - IMAGE_SIZE)\n",
    "    image = image[start_row:start_row+IMAGE_SIZE, start_col:start_col+IMAGE_SIZE]\n",
    "\n",
    "    # Normalize the pixel values to [0,1]\n",
    "    image = (image - MIN_ALTITUDE) / (MAX_ALTITUDE - MIN_ALTITUDE)\n",
    "    \n",
    "    # reshape to 28x28x1\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    # Convert to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Use tf.py_function to call the rasterio function in a tensorflow map function\n",
    "def tf_decode_image(filename):\n",
    "    return tf.py_function(decode_image, [filename], tf.float32)\n",
    "\n",
    "ds = ds.map(tf_decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "ds = ds.cache()\n",
    "\n",
    "# Use repeat() to loop over the dataset indefinitely\n",
    "ds = ds.repeat()\n",
    "\n",
    "# Shuffle and batch the dataset as before\n",
    "ds = ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Viz data and build dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do data transformation\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup connection aka iterator\n",
    "dataiterator = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in the sequential api for the generator and discriminator\n",
    "from tensorflow.keras.models import Sequential\n",
    "# Bring in the layers for the neural network\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Takes in random values and reshapes it to 7x7x128\n",
    "    # Beginnings of a generated image\n",
    "    model.add(Dense(7*7*128, input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7,7,128)))\n",
    "    \n",
    "    # Upsampling block 1 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Upsampling block 2 \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Convolutional block 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    \n",
    "    # Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    # first conv block\n",
    "    model.add(Conv2D(32, 5, input_shape = (28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Second conv block\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Second conv block\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Second conv block\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flatten then pass to dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4)) # Might be best to not have\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Construct training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Setup losses and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer for both\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Loss for both\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_opt = Adam(learning_rate=0.0001)\n",
    "d_opt = Adam(learning_rate=0.00001)\n",
    "\n",
    "g_loss = BinaryCrossentropy()\n",
    "d_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Subclass model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import base model class to subclass our training step\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 key functions\n",
    "\n",
    "class TerrainTileGan(Model):\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # Pass to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Create attributes for gen end disc\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compile(self, g_opt, d_opt, g_loss, d_loss, *args, **kwargs):\n",
    "        ## Compile w/ baseclass\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "        # Attributes for losses and optimizers\n",
    "        self.g_opt = g_opt\n",
    "        self.d_opt = d_opt\n",
    "        self.g_loss = g_loss\n",
    "        self.d_loss = d_loss\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        # get the data\n",
    "        real_images = batch\n",
    "        # 128 because we start with a linear layer w/ 128 neurons. Gets reshaped lated\n",
    "        fake_images = self.generator(tf.random.normal((128, 128, 1)), training = False)\n",
    "\n",
    "        # Train discriminator\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            # 1. pass real and fake imgs to discriminaotr\n",
    "            yhat_real = self.discriminator(real_images, training=True)\n",
    "            yhat_fake = self.discriminator(fake_images, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "            \n",
    "            # 2. cresate labels for real and fakes\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "\n",
    "            # 3. add noise to output to avoid learning too fast\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            ## Not sure if - is good idea.\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "\n",
    "            # 4. Calculate loss - BINARYCROSSENTROPY\n",
    "            total_d_loss = self.d_loss(y_realfake, yhat_realfake)\n",
    "\n",
    "        # 5. Backpropagate -- nn learn\n",
    "        dgrad = d_tape.gradient(total_d_loss, self.discriminator.trainable_variables)\n",
    "        self.d_opt.apply_gradients(zip(dgrad, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Train gen\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            # Generate new images\n",
    "            gen_images = self.generator(tf.random.normal((128, 128, 1)), training=True)\n",
    "\n",
    "            # Create predicted labels\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "\n",
    "            # Calculate loss (rewared when disc says fake is real - hence zeros)\n",
    "            total_g_loss = self.g_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "            # No need to pass real images bc we're not training discriminator\n",
    "\n",
    "        # Apply backprop\n",
    "        ggrad = g_tape.gradient(total_g_loss, self.generator.trainable_variables)\n",
    "        self.g_opt.apply_gradients(zip(ggrad, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"d_loss\":total_d_loss, \"g_loss\": total_g_loss}\n",
    "            \n",
    "    # Also option for train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Alt\n",
    "# @tf.function\n",
    "# def train_step():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of subclassed model\n",
    "terrainTileGan = TerrainTileGan(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "terrainTileGan.compile(g_opt, d_opt, g_loss, d_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Build callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create images dir for model\n",
    "!mkdir -p images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))\n",
    "            tf.summary.image(f'generated_img_{epoch}_{i}', generated_images[i], step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup tensorboard\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()), histogram_freq=1, write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "\n",
    "## CHeck if there are any .h5 files in the directory\n",
    "if len(os.listdir()) > 0:\n",
    "    # If there are, load the latest one\n",
    "    latest_gen = max(glob.glob('gen*.h5'))\n",
    "    latest_disc = max(glob.glob('disc*.h5'))\n",
    "    generator.load_weights(latest_gen)\n",
    "    discriminator.load_weights(latest_disc)\n",
    "\n",
    "def save_weights(iteration):\n",
    "    generator.save(f'gen{iteration}.h5')\n",
    "    discriminator.save(f'disc{iteration}.h5')\n",
    "\n",
    "def run_tensorboard():\n",
    "    subprocess.call(['tensorboard', '--logdir', 'logs'])\n",
    "\n",
    "# tb_thread = threading.Thread(target=run_tensorboard)\n",
    "# tb_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.5549 - g_loss: 1.3986\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.5565 - g_loss: 1.3804\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.5606 - g_loss: 1.3417\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.5439 - g_loss: 1.4735\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.5547 - g_loss: 1.3767\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.7070 - g_loss: 1.9953\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.3574 - g_loss: 2.0896\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2709 - g_loss: 2.0887\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 55ms/step - d_loss: 0.2689 - g_loss: 2.1919\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2706 - g_loss: 2.2102\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2689 - g_loss: 2.2170WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2669 - g_loss: 2.2259WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0267s vs `on_train_batch_end` time: 0.0274s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2692 - g_loss: 2.2034\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2689 - g_loss: 2.1978\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2688 - g_loss: 2.2100\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2685 - g_loss: 2.2312\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2699 - g_loss: 2.2243\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2683 - g_loss: 2.2553\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2688 - g_loss: 2.2810\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.3141\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2688 - g_loss: 2.3341\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2678 - g_loss: 2.3502\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  3/250 [..............................] - ETA: 13s - d_loss: 0.2677 - g_loss: 2.4342WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2663 - g_loss: 2.4173WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_end` time: 0.0278s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2666 - g_loss: 2.3731\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2675 - g_loss: 2.3876\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4044\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2683 - g_loss: 2.4028\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2680 - g_loss: 2.4160\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.4175\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.4188\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2680 - g_loss: 2.4361\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2675 - g_loss: 2.4501\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2684 - g_loss: 2.4554\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2765 - g_loss: 2.5445WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2659 - g_loss: 2.5224WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0268s vs `on_train_batch_end` time: 0.0274s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.4808\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4758\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2682 - g_loss: 2.4698\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2671 - g_loss: 2.4783\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.4855\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2666 - g_loss: 2.4896\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.4847\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4904\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2680 - g_loss: 2.4953\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.5006\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  1/250 [..............................] - ETA: 14s - d_loss: 0.2730 - g_loss: 2.5032WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5099\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.5116\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2674 - g_loss: 2.5049\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2681 - g_loss: 2.5086\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.5210\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2666 - g_loss: 2.5234\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.5237\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.5263\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.5332\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2659 - g_loss: 2.5393\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2775 - g_loss: 2.5093WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2725 - g_loss: 2.4557WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0267s vs `on_train_batch_end` time: 0.0275s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2671 - g_loss: 2.5360\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.3254 - g_loss: 2.3314\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2730 - g_loss: 2.6247\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2693 - g_loss: 2.6709\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.3896 - g_loss: 1.9938\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.4775 - g_loss: 2.0851\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2718 - g_loss: 1.9101\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2706 - g_loss: 1.9438\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2709 - g_loss: 1.9862\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2683 - g_loss: 2.0637\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2749 - g_loss: 2.0966WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2731 - g_loss: 2.0837WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_end` time: 0.0278s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2684 - g_loss: 2.0751\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2680 - g_loss: 2.1021\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2678 - g_loss: 2.1300\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2679 - g_loss: 2.1586\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2685 - g_loss: 2.1908\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2679 - g_loss: 2.2103\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2678 - g_loss: 2.2253\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2678 - g_loss: 2.2406\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.2538\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.2741\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  3/250 [..............................] - ETA: 13s - d_loss: 0.2612 - g_loss: 2.2742WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2651 - g_loss: 2.2800WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0262s vs `on_train_batch_end` time: 0.0282s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2674 - g_loss: 2.2835\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.2941\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.3175\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.3199\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2676 - g_loss: 2.3291\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.3352\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2671 - g_loss: 2.3364\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.3371\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2660 - g_loss: 2.3470\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2652 - g_loss: 2.3551\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2623 - g_loss: 2.3818WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2665 - g_loss: 2.3764WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0268s vs `on_train_batch_end` time: 0.0274s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.3469\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.3472\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.3494\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.3519\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.3510\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2661 - g_loss: 2.3682\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.3632\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.3715\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.3706\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.3798\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2637 - g_loss: 2.3157WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2676 - g_loss: 2.3749\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.3800\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2657 - g_loss: 2.3923\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.3865\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.3975\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.3961\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2660 - g_loss: 2.4125\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2675 - g_loss: 2.4095\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.4220\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.4273\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2535 - g_loss: 2.4796WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2640 - g_loss: 2.4559WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0269s vs `on_train_batch_end` time: 0.0275s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2674 - g_loss: 2.4254\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.4340\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.4482\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2661 - g_loss: 2.4525\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.4539\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2661 - g_loss: 2.4609\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.4554\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.4584\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.4679\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.4641\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  1/250 [..............................] - ETA: 15s - d_loss: 0.2641 - g_loss: 2.4760WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4634\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2680 - g_loss: 2.4660\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2672 - g_loss: 2.4715\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4790\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.4740\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2670 - g_loss: 2.4812\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2679 - g_loss: 2.4701\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2658 - g_loss: 2.4875\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.4837\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2671 - g_loss: 2.4921\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  3/250 [..............................] - ETA: 13s - d_loss: 0.2700 - g_loss: 2.4720WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2675 - g_loss: 2.4756WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0264s vs `on_train_batch_end` time: 0.0279s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2654 - g_loss: 2.4990\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.4912\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.4914\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.4941\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.4982\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.5012\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5117\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2675 - g_loss: 2.5073\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.5136\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2673 - g_loss: 2.5021\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2619 - g_loss: 2.5235WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2657 - g_loss: 2.5232WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0269s vs `on_train_batch_end` time: 0.0276s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.5149\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.5195\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2674 - g_loss: 2.5162\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2666 - g_loss: 2.5254\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2659 - g_loss: 2.5229\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.5193\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.5186\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.5248\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.5345\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5291\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2647 - g_loss: 2.5633WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2671 - g_loss: 2.5757WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0265s vs `on_train_batch_end` time: 0.0279s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.5303\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2671 - g_loss: 2.5379\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5305\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2669 - g_loss: 2.5207\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.5336\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2657 - g_loss: 2.5426\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2664 - g_loss: 2.5383\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5346\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.5454\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.5488\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2670 - g_loss: 2.5305WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2664 - g_loss: 2.5464WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0266s vs `on_train_batch_end` time: 0.0277s). Check your callbacks.\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2662 - g_loss: 2.5490\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2667 - g_loss: 2.5565\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2666 - g_loss: 2.5505\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5562\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.5523\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2665 - g_loss: 2.5563\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2668 - g_loss: 2.5506\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2677 - g_loss: 2.5538\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2663 - g_loss: 2.5582\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 14s 56ms/step - d_loss: 0.2661 - g_loss: 2.5622\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Epoch 1/10\n",
      "  2/250 [..............................] - ETA: 13s - d_loss: 0.2696 - g_loss: 2.5928WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "  6/250 [..............................] - ETA: 13s - d_loss: 0.2694 - g_loss: 2.5632WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0266s vs `on_train_batch_end` time: 0.0276s). Check your callbacks.\n",
      "215/250 [========================>.....] - ETA: 1s - d_loss: 0.2672 - g_loss: 2.5507"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb Cell 31\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb#X65sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb#X65sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwhile\u001b[39;00m time() \u001b[39m<\u001b[39m training_end_time:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb#X65sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     hist \u001b[39m=\u001b[39m terrainTileGan\u001b[39m.\u001b[39;49mfit(ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m250\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[ModelMonitor(), tensorboard])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb#X65sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     threading\u001b[39m.\u001b[39mThread(target\u001b[39m=\u001b[39msave_weights, args\u001b[39m=\u001b[39m(iteration,))\u001b[39m.\u001b[39mstart()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nacho/Documents/Maestria/Projecto/ttGAN_clean.ipynb#X65sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     iteration \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "duration = 60 #minutes\n",
    "epochs = 20\n",
    "steps_per_epoch = 500\n",
    "\n",
    "training_end_time = time() + 60*duration\n",
    "iteration = 0\n",
    "\n",
    "while time() < training_end_time:\n",
    "    hist = terrainTileGan.fit(ds, epochs=10, steps_per_epoch=250, callbacks=[ModelMonitor(), tensorboard])\n",
    "    threading.Thread(target=save_weights, args=(iteration,)).start()\n",
    "    iteration += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5. Test out generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Generate Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
